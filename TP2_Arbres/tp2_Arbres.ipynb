{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Rapport du TP2_Arbres\n",
        "author: IKHLEF Aimene\n",
        "date: 2023/09/28\n",
        "format: pdf\n",
        "fig-align: center\n",
        "execute:\n",
        "  enabled: true\n",
        "---"
      ],
      "id": "79e902f2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import graphviz\n",
        "from matplotlib import rc\n",
        "import seaborn as sns\n",
        "from sklearn import tree, datasets, model_selection\n",
        "from tp_arbres_source import (rand_gauss, rand_bi_gauss, rand_tri_gauss,\n",
        "                              rand_checkers, rand_clown,\n",
        "                              plot_2d, frontiere)"
      ],
      "id": "5a933d9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1\n",
        "En régression, il est possible de sélectionner une fonction de perte telle que l'erreur quadratique moyenne, qui réduit la variance et minimise la perte L2 en moyennant les nœuds terminaux. Alternativement, on peut minimiser la perte L1 en utilisant la médiane des nœuds terminaux. D'autres critères, tels que l'erreur quadratique moyenne de Friedman ou le critère de Poisson, peuvent également être envisagés.\n",
        "\n",
        "## Question 2\n",
        "\n",
        "On simule à l'aide de rand_checkers des échantillons de taille $n=456$.\n",
        "Ces données serviront à construire deux arbres, l'un utilisant le critère de Gini et l'autre utilisant l'entropie.\n",
        "On affiche ensuite les courbes donnant le pourcentage d'erreur en fonction de la profondeur de l'arbre.\n"
      ],
      "id": "7656d226"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(15)\n",
        "\n",
        "# Génération des données\n",
        "n = 456\n",
        "data = rand_checkers(n//4, n//4, n//4, n//4)\n",
        "X_train = data[:, :2]\n",
        "y_train = data[:, 2]\n",
        "\n",
        "# Fonction pour appliquer une fonction à chaque élément d'un dictionnaire de listes\n",
        "def fmap_dict_list(f, dic):\n",
        "    return {key: list(map(f, value)) for key, value in dic.items()}\n",
        "\n",
        "# Création de tous les classificateurs\n",
        "def create_all_classifiers(criterions, depths):\n",
        "    classifiers = defaultdict(list)\n",
        "    for criterion, max_depth in product(criterions, depths):\n",
        "        classifier = tree.DecisionTreeClassifier(\n",
        "            criterion=criterion,\n",
        "            max_depth=max_depth,\n",
        "        )\n",
        "        classifiers[criterion].append(classifier)\n",
        "    return classifiers\n",
        "\n",
        "# Entraînement de tous les classificateurs sur les données d'entraînement\n",
        "def fit_all_classifiers(classifiers, X_train, y_train):\n",
        "    return fmap_dict_list(\n",
        "        lambda classifier: classifier.fit(X_train, y_train),\n",
        "        classifiers\n",
        "    )\n",
        "\n",
        "# Calcul de tous les scores des classificateurs sur les données d'entraînement\n",
        "def compute_all_scores(classifiers, X_test, y_test):\n",
        "    return fmap_dict_list(\n",
        "        lambda classifier: classifier.score(X_test, y_test),\n",
        "        classifiers\n",
        "    )\n",
        "\n",
        "# Liste des critères et profondeurs à tester\n",
        "criterions = [\"gini\", \"entropy\"]\n",
        "depths = range(1, 14)\n",
        "\n",
        "# Création des classificateurs, entraînement et calcul des scores\n",
        "classifiers = create_all_classifiers(criterions, depths)\n",
        "classifiers = fit_all_classifiers(classifiers, X_train, y_train)\n",
        "scores = compute_all_scores(classifiers, X_train, y_train)\n",
        "\n",
        "# Affichage des scores\n",
        "print(scores)\n",
        "\n",
        "# Tracé des courbes de score\n",
        "plt.figure()\n",
        "for criterion in scores.keys():\n",
        "    plt.plot(depths, scores[criterion], label=f\"{criterion} score\")\n",
        "\n",
        "plt.xlabel('Max depth')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.legend()\n",
        "plt.draw()"
      ],
      "id": "c3e6de4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ici on trouve que la profondeur qui minimise le pourcentage d'erreur (ou maximise le score) est tout simplement la profondeur maximale de notre boucle, ici sa valeur est de 12.\n",
        "\n",
        "## Question 3\n",
        "\n",
        "plus la profondeur sera grande, plus l'erreur sera petite. Ainsi avec les profondeurs testées (de 1 à 13)\n"
      ],
      "id": "b7f77e7b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(15)\n",
        "\n",
        "# Trouver la meilleure profondeur\n",
        "best_depth = np.argmax(scores[\"entropy\"]) + 1\n",
        "assert best_depth == 12\n",
        "\n",
        "# Sélectionner le meilleur classificateur\n",
        "best_classifier = classifiers[\"entropy\"][best_depth - 1]\n",
        "\n",
        "# Tracer les frontières de décision\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Tracé 1\n",
        "plt.subplot(2, 2, 1)\n",
        "frontiere(\n",
        "    lambda x: best_classifier.predict(x.reshape((1, -1))),\n",
        "    X_train, y_train,\n",
        "    step=100, samples=False\n",
        ")\n",
        "\n",
        "# Tracé 2\n",
        "plt.subplot(2, 1, 1)\n",
        "plot_2d(X_train, y_train)\n",
        "frontiere(\n",
        "    lambda x: best_classifier.predict(x.reshape((1, -1))),\n",
        "    X_train, y_train,\n",
        "    step=100, samples=False\n",
        ")"
      ],
      "id": "89df0c57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le modèle avec une profondeur maximale (dans ce cas, 12) présente un score très proche de 1, ce qui indique un surajustement du modèle. Cela signifie que le modèle ne généralisera pas bien sur de nouvelles données, comme illustré dans la figure.\n",
        "\n",
        "## Question 4\n"
      ],
      "id": "1c229eef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "\n",
        "tree.plot_tree(dt_entropy)\n",
        "data = tree.export_graphviz(dt_entropy, filled=True, rounded=True)\n",
        "graph = graphviz.Source(data)\n",
        "graph.render('./binary_tree_entropy', format='pdf')"
      ],
      "id": "3da53a5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Arbre de décision](./binary_tree_entropy.pdf)\n",
        "\n",
        "Voici l'arbre de décision résultant, où chaque nœud représente une condition vraie ou fausse qui détermine le partitionnement des données. Si la condition est vraie, nous continuons vers le nœud suivant correspondant, sinon nous passons au nœud correspondant à \"faux\". Cette procédure se répète jusqu'à ce que nous atteignions la profondeur maximale de l'arbre.\n",
        "\n",
        "## Question 5\n",
        "\n",
        "On va maintenant utiliser les arbres précedemment trouvés pour calculer le score sur un nouvel échantillon test avec $n=160$\n"
      ],
      "id": "52c37870"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_test = 160\n",
        "\n",
        "# Générer des données de test\n",
        "data_test = rand_checkers(n_test//4, n_test//4, n_test//4, n_test//4)\n",
        "X_test = data_test[:, :2]\n",
        "y_test = data_test[:, 2]\n",
        "\n",
        "# Calculer les scores sur les données de test\n",
        "scores_test = compute_all_scores(classifiers, X_test, y_test)\n",
        "\n",
        "# Tracer les courbes de score pour les données d'entraînement et de test\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i, criterion in enumerate(scores.keys()):\n",
        "    plt.subplot(2, 1, i+1)\n",
        "\n",
        "    # Tracer le score pour les données d'entraînement\n",
        "    plt.plot(depths, scores[criterion], label=f\"Training {criterion.capitalize()} Score\")\n",
        "    print(f\"Training {criterion} Scores: {scores[criterion]}\")\n",
        "\n",
        "    # Tracer le score pour les données de test\n",
        "    plt.plot(depths, scores_test[criterion], label=f\"Test {criterion.capitalize()} Score\")\n",
        "    print(f\"Test {criterion} Scores: {scores_test[criterion]}\")\n",
        "\n",
        "    plt.title(f\"{criterion.capitalize()} Criterion\", weight=\"bold\")\n",
        "    plt.xlabel(\"Max Depth\")\n",
        "    plt.ylabel(\"Accuracy Score\")\n",
        "    plt.legend()\n",
        "\n",
        "plt.draw()"
      ],
      "id": "08b95650",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous constatons que la profondeur optimale pour maximiser le score est de 9, que ce soit pour le critère de Gini ou pour l'entropie. Ainsi, nous avons sélectionné un arbre moins profond par rapport à nos précédents résultats, ce qui contribue à réduire le risque de surajustement.\n",
        "\n",
        "\n",
        "## Question 6\n"
      ],
      "id": "6422c533"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "digits = datasets.load_digits()\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(digits.data, digits.target, train_size=0.8, test_size=0.2)\n",
        "\n",
        "# Initialisation des classificateurs pour l'entropie et le Gini\n",
        "dt_entropy = tree.DecisionTreeClassifier(criterion='entropy')\n",
        "dt_gini = tree.DecisionTreeClassifier(criterion='gini')\n",
        "\n",
        "# Entraîner les classificateurs sur les données d'entraînement\n",
        "dt_entropy.fit(X_train, Y_train)\n",
        "dt_gini.fit(X_train, Y_train)\n",
        "\n",
        "# Définir la limite de profondeur maximale à tester\n",
        "dmax = 15\n",
        "\n",
        "# Initialiser les tableaux pour stocker les scores\n",
        "scores_entropy_test = np.zeros(dmax)\n",
        "scores_gini_test = np.zeros(dmax)\n",
        "scores_entropy_train = np.zeros(dmax)\n",
        "scores_gini_train = np.zeros(dmax)\n",
        "\n",
        "# Parcourir différentes profondeurs et calculer les scores\n",
        "for i in range(dmax):\n",
        "    # Classificateurs avec différentes profondeurs\n",
        "    dt_entropy = tree.DecisionTreeClassifier(criterion='entropy', max_depth=i+1)\n",
        "    dt_gini = tree.DecisionTreeClassifier(criterion='gini', max_depth=i+1)\n",
        "\n",
        "    # Entraîner les classificateurs\n",
        "    dt_entropy.fit(X_train, Y_train)\n",
        "    dt_gini.fit(X_train, Y_train)\n",
        "\n",
        "    # Calculer les scores pour les données d'entraînement et de test\n",
        "    scores_entropy_test[i] = dt_entropy.score(X_test, Y_test)\n",
        "    scores_entropy_train[i] = dt_entropy.score(X_train, Y_train)\n",
        "    scores_gini_test[i] = dt_gini.score(X_test, Y_test)\n",
        "    scores_gini_train[i] = dt_gini.score(X_train, Y_train)\n",
        "\n",
        "# Tracer les scores sur les ensembles d'entraînement et de test\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
        "\n",
        "# Scores d'entraînement\n",
        "axes[0].plot(scores_entropy_train, label='Entropy criterion', marker='o')\n",
        "axes[0].plot(scores_gini_train, label='Gini criterion', marker='x')\n",
        "axes[0].legend(loc='lower right')\n",
        "axes[0].set_title('Score on training set')\n",
        "axes[0].set_xlabel('Max depth')\n",
        "axes[0].set_ylabel('Accuracy Score')\n",
        "axes[0].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Scores de test\n",
        "axes[1].plot(scores_entropy_test, label='Entropy criterion', marker='o')\n",
        "axes[1].plot(scores_gini_test, label='Gini criterion', marker='x')\n",
        "axes[1].legend(loc='lower right')\n",
        "axes[1].set_title('Score on test set')\n",
        "axes[1].set_xlabel('Max depth')\n",
        "axes[1].set_ylabel('Accuracy Score')\n",
        "axes[1].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Scores with entropy criterion: \", scores_entropy)\n",
        "print(\"Scores with Gini criterion: \", scores_gini)"
      ],
      "id": "79f0637f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous observons les mêmes problèmes de surapprentissage que dans notre jeu de données simulées. En effet, la précision sur les données d'entraînement atteint presque 98 %, tandis que sur les données de test, elle ne dépasse jamais les 90 %. Cela signifie que dans le premier cas, la précision est surestimée.\n",
        "\n",
        "## Question 7\n",
        "\n",
        "On utilise la validation croisée pour effectuer le choix du paramètre de profondeur.\n"
      ],
      "id": "cd136104"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "classifiers = create_all_classifiers(criterions, depths)\n",
        "\n",
        "# les scores de validation croisée pour chaque classificateur\n",
        "scores_crossval = fmap_dict_list(\n",
        "    lambda classifier: np.mean(model_selection.cross_val_score(\n",
        "        classifier, X, y,\n",
        "        cv=model_selection.KFold(5, shuffle=True, random_state=0)\n",
        "    )),\n",
        "    classifiers\n",
        ")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i, criterion in enumerate(scores.keys()):\n",
        "    plt.subplot(2, 1, i + 1)\n",
        "\n",
        "    \n",
        "    plt.plot(depths, scores[criterion], label=f\"Training {criterion.capitalize()} Score\")\n",
        "\n",
        "    # Tracer le score pour les données de test\n",
        "    plt.plot(depths, scores_test[criterion], label=f\"Test {criterion.capitalize()} Score\")\n",
        "\n",
        "    # Tracer le score pour la validation croisée\n",
        "    plt.plot(depths, scores_crossval[criterion], label=f\"Cross Validation {criterion.capitalize()} Score\")\n",
        "\n",
        "    plt.title(f\"{criterion.capitalize()} Criterion\", weight=\"bold\")\n",
        "    plt.xlabel(\"Max Depth\")\n",
        "    plt.ylabel(\"Accuracy Score\")\n",
        "    plt.legend()\n",
        "\n",
        "plt.draw()"
      ],
      "id": "9dd17884",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 8\n",
        "\n",
        "Dans cette question on affiche la courbe d'apprentissage qui mesure l'effet du score en fonction du nombre de données durant la période d'apprentissage du modèle.\n"
      ],
      "id": "da538021"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for criterion in classifiers.keys():\n",
        "    fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(15, 17), sharey=True)\n",
        "\n",
        "    skip = 2\n",
        "    for i, classifier in enumerate(classifiers[criterion][:12:skip]):\n",
        "        sub_ax = ax[i // 2, i % 2]\n",
        "\n",
        "        model_selection.LearningCurveDisplay.from_estimator(\n",
        "            classifier,\n",
        "            X=X, y=y,\n",
        "            train_sizes=np.linspace(0.001, 1, 20),\n",
        "            line_kw={\"marker\": \"o\"},\n",
        "            std_display_style=\"fill_between\",\n",
        "            score_name=\"Accuracy\",\n",
        "            ax=sub_ax,\n",
        "            cv=model_selection.KFold(5, shuffle=True, random_state=0)\n",
        "        )\n",
        "\n",
        "    \n",
        "        sub_ax.set_title(\n",
        "            (f\"Learning Curve for {criterion.capitalize()} criterion \"\n",
        "             f\"(max_depth={i * skip + 1})\"),\n",
        "            weight=\"bold\"\n",
        "        )\n",
        "\n",
        "        sub_ax.legend([\"Training Score\", \"Test Score\"])"
      ],
      "id": "aaa258f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dans notre situation, la performance sur l'ensemble d'apprentissage reste élevée indépendamment de la taille de l'échantillon. Alors, la performance sur l'ensemble de test augmente à mesure que la taille de l'échantillon d'apprentissage augmente, mais elle atteint un plateau à un certain point."
      ],
      "id": "163ac2b9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}